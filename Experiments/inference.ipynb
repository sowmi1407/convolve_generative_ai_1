{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a7caf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Path to your trained model\n",
    "MODEL_PATH = \"/content/drive/MyDrive/Convolve/model/stamp_signature_detection_55/stamp_signature_detector/weights/best.pt\"\n",
    "\n",
    "# Input folder containing test images\n",
    "INPUT_FOLDER = \"/content/drive/MyDrive/Convolve/data/train\"\n",
    "\n",
    "# Output folder for results\n",
    "OUTPUT_FOLDER = \"/content/drive/MyDrive/Convolve/data/train_results_55_stamp_sign\"\n",
    "\n",
    "# Inference parameters\n",
    "CONFIDENCE_THRESHOLD = 0.25 # Minimum confidence for detection\n",
    "IOU_THRESHOLD = 0.45  # NMS IoU threshold\n",
    "IMAGE_SIZE = 736    # Input image size\n",
    "\n",
    "# Class mapping - MUST MATCH YOUR TRAINED MODEL!\n",
    "CLASS_NAMES = {\n",
    "    0: 'signature',  # Class 0: Signature\n",
    "    1: 'stamp'       # Class 1: Stamp\n",
    "}\n",
    "\n",
    "# Visualization settings for each class\n",
    "CLASS_COLORS = {\n",
    "    0: (0, 0, 255),    # Red for signatures (class 0)\n",
    "    1: (0, 255, 0)     # Green for stamps (class 1)\n",
    "}\n",
    "\n",
    "BOX_THICKNESS = 2\n",
    "TEXT_COLOR = (255, 255, 255)  # White text\n",
    "TEXT_THICKNESS = 2\n",
    "FONT_SCALE = 0.6\n",
    "\n",
    "# Save options\n",
    "SAVE_IMAGES = True  # Save images with drawn bounding boxes\n",
    "SAVE_ANNOTATIONS = True  # Save detection annotations as JSON\n",
    "SAVE_CROPPED_OBJECTS = True  # Save cropped regions for both stamps and signatures\n",
    "SEPARATE_BY_CLASS = True  # Save cropped objects in separate folders by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccc321c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_output_folders():\n",
    "    \"\"\"Creates organized output folder structure\"\"\"\n",
    "    folders = {\n",
    "        'annotated_images': os.path.join(OUTPUT_FOLDER, 'annotated_images'),\n",
    "        'annotations': os.path.join(OUTPUT_FOLDER, 'annotations'),\n",
    "        'no_detections': os.path.join(OUTPUT_FOLDER, 'no_detections'),\n",
    "        'summary': OUTPUT_FOLDER\n",
    "    }\n",
    "    \n",
    "    # Add folders for cropped objects\n",
    "    if SAVE_CROPPED_OBJECTS:\n",
    "        if SEPARATE_BY_CLASS:\n",
    "            folders['cropped_stamps'] = os.path.join(OUTPUT_FOLDER, 'cropped_objects', 'stamps')\n",
    "            folders['cropped_signatures'] = os.path.join(OUTPUT_FOLDER, 'cropped_objects', 'signatures')\n",
    "        else:\n",
    "            folders['cropped_objects'] = os.path.join(OUTPUT_FOLDER, 'cropped_objects')\n",
    "    \n",
    "    for folder in folders.values():\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "    \n",
    "    return folders\n",
    "\n",
    "def draw_obb_on_image(image, obb_points, label, confidence, color, thickness):\n",
    "    \"\"\"\n",
    "    Draws oriented bounding box on image\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of image\n",
    "        obb_points: array of 4 corner points [[x1,y1], [x2,y2], [x3,y3], [x4,y4]]\n",
    "        label: class label string\n",
    "        confidence: detection confidence\n",
    "        color: BGR color tuple\n",
    "        thickness: line thickness\n",
    "    \"\"\"\n",
    "    # Convert points to integer\n",
    "    points = np.array(obb_points, dtype=np.int32)\n",
    "    \n",
    "    # Draw the rotated rectangle\n",
    "    cv2.polylines(image, [points], isClosed=True, color=color, thickness=thickness)\n",
    "    \n",
    "    # Add label with confidence\n",
    "    text = f\"{label} {confidence:.2f}\"\n",
    "    \n",
    "    # Get text size for background rectangle\n",
    "    (text_width, text_height), baseline = cv2.getTextSize(\n",
    "        text, cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE, TEXT_THICKNESS\n",
    "    )\n",
    "    \n",
    "    # Draw background rectangle for text\n",
    "    text_x, text_y = points[0]\n",
    "    cv2.rectangle(\n",
    "        image,\n",
    "        (text_x, text_y - text_height - baseline - 5),\n",
    "        (text_x + text_width, text_y),\n",
    "        color,\n",
    "        -1  # Filled rectangle\n",
    "    )\n",
    "    \n",
    "    # Draw text\n",
    "    cv2.putText(\n",
    "        image,\n",
    "        text,\n",
    "        (text_x, text_y - baseline),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        FONT_SCALE,\n",
    "        TEXT_COLOR,\n",
    "        TEXT_THICKNESS\n",
    "    )\n",
    "    \n",
    "    return image\n",
    "\n",
    "def get_cropped_region(image, obb_points):\n",
    "    \"\"\"\n",
    "    Extracts and returns the rotated cropped region\n",
    "    \n",
    "    Args:\n",
    "        image: numpy array of image\n",
    "        obb_points: array of 4 corner points\n",
    "    \n",
    "    Returns:\n",
    "        cropped image region\n",
    "    \"\"\"\n",
    "    # Get the rotated bounding rectangle\n",
    "    rect = cv2.minAreaRect(obb_points.astype(np.float32))\n",
    "    box = cv2.boxPoints(rect)\n",
    "    box = np.int32(box)\n",
    "    \n",
    "    # Get width and height of the rotated rectangle\n",
    "    width = int(rect[1][0])\n",
    "    height = int(rect[1][1])\n",
    "    \n",
    "    # Avoid zero dimensions\n",
    "    if width == 0 or height == 0:\n",
    "        return None\n",
    "    \n",
    "    # Get rotation matrix\n",
    "    src_pts = box.astype(\"float32\")\n",
    "    dst_pts = np.array([\n",
    "        [0, height-1],\n",
    "        [0, 0],\n",
    "        [width-1, 0],\n",
    "        [width-1, height-1]\n",
    "    ], dtype=\"float32\")\n",
    "    \n",
    "    # Compute transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(src_pts, dst_pts)\n",
    "    \n",
    "    # Warp the image\n",
    "    warped = cv2.warpPerspective(image, M, (width, height))\n",
    "    \n",
    "    return warped\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf6efc8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def process_images_batch(model_path, input_folder, output_folders):\n",
    "    \"\"\"\n",
    "    Process all images in a folder and detect stamps and signatures\n",
    "    \n",
    "    Args:\n",
    "        model_path: path to trained YOLO model\n",
    "        input_folder: folder containing test images\n",
    "        output_folders: dictionary of output folder paths\n",
    "    \n",
    "    Returns:\n",
    "        summary statistics dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load the trained model\n",
    "    print(f\"Loading model from: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "    # Verify class names\n",
    "    print(f\"Model classes: {model.names}\")\n",
    "    \n",
    "    # Get list of image files\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif']\n",
    "    image_files = [\n",
    "        f for f in os.listdir(input_folder)\n",
    "        if os.path.splitext(f.lower())[1] in image_extensions\n",
    "    ]\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {input_folder}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nFound {len(image_files)} images to process\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Statistics tracking\n",
    "    stats = {\n",
    "        'total_images': len(image_files),\n",
    "        'images_with_detections': 0,\n",
    "        'images_without_detections': 0,\n",
    "        'total_stamps_detected': 0,\n",
    "        'total_signatures_detected': 0,\n",
    "        'total_detections': 0,\n",
    "        'processing_time': 0,\n",
    "        'detections': [],\n",
    "        'no_detection_files': [],\n",
    "        'class_distribution': {\n",
    "            'stamp': 0,\n",
    "            'signature': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    # Process each image\n",
    "    for idx, image_file in enumerate(image_files, 1):\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        image_name = Path(image_file).stem\n",
    "        image_ext = Path(image_file).suffix\n",
    "        \n",
    "        print(f\"\\n[{idx}/{len(image_files)}] Processing: {image_file}\")\n",
    "        \n",
    "        # Read original image for visualization\n",
    "        original_image = cv2.imread(image_path)\n",
    "        \n",
    "        # Run inference\n",
    "        results = model.predict(\n",
    "            source=image_path,\n",
    "            conf=CONFIDENCE_THRESHOLD,\n",
    "            iou=IOU_THRESHOLD,\n",
    "            imgsz=IMAGE_SIZE,\n",
    "            verbose=False\n",
    "        )\n",
    "        \n",
    "        # Get results for this image\n",
    "        result = results[0]\n",
    "        \n",
    "        # Check if OBB (oriented bounding boxes) are detected\n",
    "        if result.obb is not None and len(result.obb) > 0:\n",
    "            \n",
    "            # Count detections by class\n",
    "            stamp_count = 0\n",
    "            signature_count = 0\n",
    "            \n",
    "            # Prepare annotation data\n",
    "            image_annotations = {\n",
    "                'image_name': image_file,\n",
    "                'image_path': image_path,\n",
    "                'detections': {\n",
    "                    'stamps': [],\n",
    "                    'signatures': []\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            # Process each detection\n",
    "            for det_idx, (obb, conf, cls) in enumerate(zip(result.obb.xyxyxyxy, result.obb.conf, result.obb.cls)):\n",
    "                # Get OBB points (4 corners)\n",
    "                obb_points = obb.cpu().numpy()\n",
    "                confidence = float(conf.cpu().numpy())\n",
    "                class_id = int(cls.cpu().numpy())\n",
    "                class_name = model.names[class_id]\n",
    "                \n",
    "                # Count by class\n",
    "                if class_id == 0:  # Stamp\n",
    "                    stamp_count += 1\n",
    "                    detection_key = 'stamps'\n",
    "                elif class_id == 1:  # Signature\n",
    "                    signature_count += 1\n",
    "                    detection_key = 'signatures'\n",
    "                else:\n",
    "                    continue  # Skip unknown classes\n",
    "                \n",
    "                # Save detection info\n",
    "                detection_info = {\n",
    "                    'detection_id': det_idx + 1,\n",
    "                    'class': class_name,\n",
    "                    'class_id': class_id,\n",
    "                    'confidence': confidence,\n",
    "                    'obb_points': obb_points.tolist()\n",
    "                }\n",
    "                image_annotations['detections'][detection_key].append(detection_info)\n",
    "                \n",
    "                # Get color for this class\n",
    "                color = CLASS_COLORS.get(class_id, (255, 255, 255))\n",
    "                \n",
    "                # Draw bounding box on image\n",
    "                original_image = draw_obb_on_image(\n",
    "                    original_image,\n",
    "                    obb_points,\n",
    "                    class_name,\n",
    "                    confidence,\n",
    "                    color,\n",
    "                    BOX_THICKNESS\n",
    "                )\n",
    "                \n",
    "                # Save cropped object region\n",
    "                if SAVE_CROPPED_OBJECTS:\n",
    "                    cropped_object = get_cropped_region(cv2.imread(image_path), obb_points)\n",
    "                    \n",
    "                    if cropped_object is not None:\n",
    "                        if SEPARATE_BY_CLASS:\n",
    "                            if class_id == 0:\n",
    "                                crop_folder = output_folders['cropped_stamps']\n",
    "                                crop_filename = f\"{image_name}_stamp_{stamp_count}{image_ext}\"\n",
    "                            else:\n",
    "                                crop_folder = output_folders['cropped_signatures']\n",
    "                                crop_filename = f\"{image_name}_signature_{signature_count}{image_ext}\"\n",
    "                        else:\n",
    "                            crop_folder = output_folders['cropped_objects']\n",
    "                            crop_filename = f\"{image_name}_{class_name}_{det_idx+1}{image_ext}\"\n",
    "                        \n",
    "                        crop_path = os.path.join(crop_folder, crop_filename)\n",
    "                        cv2.imwrite(crop_path, cropped_object)\n",
    "            \n",
    "            # Update statistics\n",
    "            total_detected = stamp_count + signature_count\n",
    "            if total_detected > 0:\n",
    "                stats['images_with_detections'] += 1\n",
    "                stats['total_stamps_detected'] += stamp_count\n",
    "                stats['total_signatures_detected'] += signature_count\n",
    "                stats['total_detections'] += total_detected\n",
    "                stats['class_distribution']['stamp'] += stamp_count\n",
    "                stats['class_distribution']['signature'] += signature_count\n",
    "                \n",
    "                print(f\"  ✓ Found: {stamp_count} stamp(s), {signature_count} signature(s)\")\n",
    "                \n",
    "                # Save annotated image\n",
    "                if SAVE_IMAGES:\n",
    "                    output_image_path = os.path.join(\n",
    "                        output_folders['annotated_images'],\n",
    "                        f\"{image_name}_annotated{image_ext}\"\n",
    "                    )\n",
    "                    cv2.imwrite(output_image_path, original_image)\n",
    "                \n",
    "                # Save annotations as JSON\n",
    "                if SAVE_ANNOTATIONS:\n",
    "                    annotation_path = os.path.join(\n",
    "                        output_folders['annotations'],\n",
    "                        f\"{image_name}.json\"\n",
    "                    )\n",
    "                    with open(annotation_path, 'w') as f:\n",
    "                        json.dump(image_annotations, f, indent=2)\n",
    "                \n",
    "                stats['detections'].append(image_annotations)\n",
    "            else:\n",
    "                print(f\"  ✗ No stamps or signatures detected\")\n",
    "                stats['images_without_detections'] += 1\n",
    "                \n",
    "                # Copy to no detections folder\n",
    "                no_detection_path = os.path.join(output_folders['no_detections'], image_file)\n",
    "                shutil.copy(image_path, no_detection_path)\n",
    "                stats['no_detection_files'].append(image_file)\n",
    "        else:\n",
    "            print(f\"  ✗ No detections\")\n",
    "            stats['images_without_detections'] += 1\n",
    "            \n",
    "            # Copy to no detections folder\n",
    "            no_detection_path = os.path.join(output_folders['no_detections'], image_file)\n",
    "            shutil.copy(image_path, no_detection_path)\n",
    "            stats['no_detection_files'].append(image_file)\n",
    "    \n",
    "    # Calculate processing time\n",
    "    end_time = datetime.now()\n",
    "    stats['processing_time'] = (end_time - start_time).total_seconds()\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4249a9a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def save_summary_report(stats, output_folder):\n",
    "    \"\"\"Saves a summary report of the inference results\"\"\"\n",
    "    \n",
    "    report_path = os.path.join(output_folder, 'detection_summary.json')\n",
    "    \n",
    "    summary = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'model_path': MODEL_PATH,\n",
    "        'total_images_processed': stats['total_images'],\n",
    "        'images_with_detections': stats['images_with_detections'],\n",
    "        'images_without_detections': stats['images_without_detections'],\n",
    "        'total_detections': stats['total_detections'],\n",
    "        'stamps_detected': stats['total_stamps_detected'],\n",
    "        'signatures_detected': stats['total_signatures_detected'],\n",
    "        'class_distribution': stats['class_distribution'],\n",
    "        'average_detections_per_image': stats['total_detections'] / stats['total_images'] if stats['total_images'] > 0 else 0,\n",
    "        'processing_time_seconds': stats['processing_time'],\n",
    "        'average_time_per_image': stats['processing_time'] / stats['total_images'] if stats['total_images'] > 0 else 0,\n",
    "        'detections': stats['detections'],\n",
    "        'no_detection_files': stats['no_detection_files']\n",
    "    }\n",
    "    \n",
    "    with open(report_path, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    # Create comprehensive text summary\n",
    "    text_report_path = os.path.join(output_folder, 'detection_summary.txt')\n",
    "    with open(text_report_path, 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"STAMP & SIGNATURE DETECTION SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Timestamp: {summary['timestamp']}\\n\")\n",
    "        f.write(f\"Model: {MODEL_PATH}\\n\\n\")\n",
    "        \n",
    "        f.write(\"OVERALL STATISTICS\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        f.write(f\"Total images processed: {summary['total_images_processed']}\\n\")\n",
    "        f.write(f\"Images with detections: {summary['images_with_detections']}\\n\")\n",
    "        f.write(f\"Images without detections: {summary['images_without_detections']}\\n\")\n",
    "        f.write(f\"Detection rate: {(summary['images_with_detections']/summary['total_images_processed']*100):.1f}%\\n\\n\")\n",
    "        \n",
    "        f.write(\"DETECTION BREAKDOWN\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        f.write(f\"Total detections: {summary['total_detections']}\\n\")\n",
    "        f.write(f\"  - Stamps (class 0): {summary['stamps_detected']}\\n\")\n",
    "        f.write(f\"  - Signatures (class 1): {summary['signatures_detected']}\\n\")\n",
    "        f.write(f\"Average detections per image: {summary['average_detections_per_image']:.2f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"PERFORMANCE\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        f.write(f\"Processing time: {summary['processing_time_seconds']:.2f} seconds\\n\")\n",
    "        f.write(f\"Average time per image: {summary['average_time_per_image']:.2f} seconds\\n\")\n",
    "    \n",
    "    # Create separate report for images without detections\n",
    "    no_detections_report_path = os.path.join(output_folder, 'no_detections_list.txt')\n",
    "    with open(no_detections_report_path, 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"IMAGES WITHOUT DETECTIONS\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Total images without detections: {len(stats['no_detection_files'])}\\n\\n\")\n",
    "        f.write(\"List of files:\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        for idx, filename in enumerate(stats['no_detection_files'], 1):\n",
    "            f.write(f\"{idx}. {filename}\\n\")\n",
    "    \n",
    "    # Create class-specific reports\n",
    "    stamps_report_path = os.path.join(output_folder, 'stamps_detected_summary.txt')\n",
    "    with open(stamps_report_path, 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"STAMPS DETECTION SUMMARY (CLASS 0)\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Total stamps detected: {stats['total_stamps_detected']}\\n\")\n",
    "        f.write(f\"Images with stamps: {sum(1 for d in stats['detections'] if d['detections']['stamps'])}\\n\\n\")\n",
    "        f.write(\"Detections by image:\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        for detection in stats['detections']:\n",
    "            if detection['detections']['stamps']:\n",
    "                f.write(f\"{detection['image_name']}: {len(detection['detections']['stamps'])} stamp(s)\\n\")\n",
    "    \n",
    "    signatures_report_path = os.path.join(output_folder, 'signatures_detected_summary.txt')\n",
    "    with open(signatures_report_path, 'w') as f:\n",
    "        f.write(\"=\"*60 + \"\\n\")\n",
    "        f.write(\"SIGNATURES DETECTION SUMMARY (CLASS 1)\\n\")\n",
    "        f.write(\"=\"*60 + \"\\n\\n\")\n",
    "        f.write(f\"Total signatures detected: {stats['total_signatures_detected']}\\n\")\n",
    "        f.write(f\"Images with signatures: {sum(1 for d in stats['detections'] if d['detections']['signatures'])}\\n\\n\")\n",
    "        f.write(\"Detections by image:\\n\")\n",
    "        f.write(\"-\" * 60 + \"\\n\")\n",
    "        for detection in stats['detections']:\n",
    "            if detection['detections']['signatures']:\n",
    "                f.write(f\"{detection['image_name']}: {len(detection['detections']['signatures'])} signature(s)\\n\")\n",
    "    \n",
    "    return report_path, text_report_path, no_detections_report_path, stamps_report_path, signatures_report_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216668b7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"YOLOv8-OBB BATCH DETECTION\")\n",
    "    print(\"Stamps & Signatures Detection\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # Check if model exists\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"Error: Model not found at {MODEL_PATH}\")\n",
    "        print(\"Please update MODEL_PATH to point to your trained model\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Check if input folder exists\n",
    "    if not os.path.exists(INPUT_FOLDER):\n",
    "        print(f\"Error: Input folder not found at {INPUT_FOLDER}\")\n",
    "        print(\"Please update INPUT_FOLDER to point to your test images\")\n",
    "        exit(1)\n",
    "    \n",
    "    # Create output folders\n",
    "    print(\"Creating output folders...\")\n",
    "    output_folders = create_output_folders()\n",
    "    \n",
    "    # Process images\n",
    "    print(\"\\nStarting batch processing...\")\n",
    "    stats = process_images_batch(MODEL_PATH, INPUT_FOLDER, output_folders)\n",
    "    \n",
    "    if stats:\n",
    "        # Save summary report\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Processing Complete!\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        reports = save_summary_report(stats, OUTPUT_FOLDER)\n",
    "        json_report, text_report, no_detections_report, stamps_report, signatures_report = reports\n",
    "        \n",
    "        print(f\"\\nResults Summary:\")\n",
    "        print(f\"  Total images processed: {stats['total_images']}\")\n",
    "        print(f\"  Images with detections: {stats['images_with_detections']}\")\n",
    "        print(f\"  Images without detections: {stats['images_without_detections']}\")\n",
    "        print(f\"  Total stamps detected: {stats['total_stamps_detected']}\")\n",
    "        print(f\"  Total signatures detected: {stats['total_signatures_detected']}\")\n",
    "        print(f\"  Processing time: {stats['processing_time']:.2f} seconds\")\n",
    "        \n",
    "        print(f\"\\nOutput saved to: {OUTPUT_FOLDER}\")\n",
    "        print(f\"  - Annotated images: {output_folders['annotated_images']}\")\n",
    "        if SEPARATE_BY_CLASS:\n",
    "            print(f\"  - Cropped stamps: {output_folders['cropped_stamps']}\")\n",
    "            print(f\"  - Cropped signatures: {output_folders['cropped_signatures']}\")\n",
    "        else:\n",
    "            print(f\"  - Cropped objects: {output_folders['cropped_objects']}\")\n",
    "        print(f\"  - JSON annotations: {output_folders['annotations']}\")\n",
    "        print(f\"  - Images without detections: {output_folders['no_detections']}\")\n",
    "        print(f\"  - Summary report: {json_report}\")\n",
    "        print(f\"  - Text report: {text_report}\")\n",
    "        print(f\"  - No detections list: {no_detections_report}\")\n",
    "        print(f\"  - Stamps summary: {stamps_report}\")\n",
    "        print(f\"  - Signatures summary: {signatures_report}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
